{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "6f52424e-f841-4ec9-a83a-9e1fe3e06f1e",
      "cell_type": "markdown",
      "source": "# Trabajo #1: An√°lisis de Face Tracking y Visi√≥n por Computadora\n**Proyecto de M√©todos Num√©ricos**\n\n### 1. ¬øQu√© es MindAR?\nMindAR es una biblioteca de software de c√≥digo abierto y ligera dise√±ada para desarrollar experiencias de Realidad Aumentada (AR) en la web. Permite el reconocimiento de im√°genes y seguimiento facial directamente en el navegador utilizando tecnolog√≠as est√°ndar como WebGL y WebAssembly, eliminando la necesidad de instalar aplicaciones externas.\n\n### 2. ¬øQu√© es OpenCV?\nOpenCV (Open Source Computer Vision Library) es la biblioteca de visi√≥n artificial de c√≥digo abierto m√°s utilizada a nivel mundial. Provee una infraestructura com√∫n para aplicaciones de visi√≥n por computadora y contiene m√°s de 2500 algoritmos optimizados para tareas como detecci√≥n de rostros, identificaci√≥n de objetos, clasificaci√≥n de acciones en video, rastreo de movimientos y procesamiento de im√°genes (filtros, bordes, transformaciones).\n\n### 3. ¬øDe manera interna MindAR usa OpenCV?\n**No.** Aunque ambas herramientas procesan im√°genes, MindAR no depende de OpenCV.\n* **MindAR** est√° construida sobre TensorFlow.js y utiliza modelos de aprendizaje profundo (Deep Learning) propietarios y ligeros para realizar la detecci√≥n y seguimiento de caracter√≠sticas faciales o im√°genes planas.\n* **OpenCV** se basa en algoritmos cl√°sicos de procesamiento de matrices de p√≠xeles, mientras que MindAR se basa en inferencia de redes neuronales.\n\n### 4. ¬øSe puede utilizar OpenCV en JavaScript?\n**S√≠.** Existe una versi√≥n oficial llamada OpenCV.js. Mediante la tecnolog√≠a WebAssembly (Wasm), el c√≥digo original de C++ de OpenCV es compilado para que pueda ser ejecutado directamente por el navegador web (lado del cliente) con un rendimiento cercano al nativo, permitiendo realizar procesamiento de im√°genes complejo en tiempo real dentro de p√°ginas web.\n\n### 5. ¬øPara qu√© sirve el algoritmo de Canny Edge Detection?\nEl algoritmo de Canny es una t√©cnica de procesamiento de im√°genes utilizada para detectar bordes de manera robusta. Es considerado el algoritmo est√°ndar √≥ptimo para esta tarea porque cumple tres criterios clave:\n1.  **Detecci√≥n:** Baja tasa de error (encuentra todos los bordes reales).\n2.  **Localizaci√≥n:** Los puntos detectados deben estar lo m√°s cerca posible del borde real.\n3.  **Respuesta √∫nica:** Debe marcar una sola l√≠nea por cada borde (evita bordes gruesos o m√∫ltiples respuestas al mismo contorno).\n\n### 6. Ejemplo del algoritmo de Canny Edge Detection en JavaScript\n",
      "metadata": {}
    },
    {
      "id": "cacbbd02-d432-4795-b79e-0bbcdca61cc0",
      "cell_type": "code",
      "source": "%%html\n<div style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h3>M√©todo Canny Edge(Derivadas y Bordes)</h3>\n    <video id=\"v_canny_pro\" width=\"640\" height=\"480\" style=\"display:none\" playsinline></video>\n    <canvas id=\"c_canny_pro\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #27ae60; border-radius: 10px;\"></canvas>\n    <div style=\"margin-top: 15px;\">\n        <button id=\"btn_on_canny\" onclick=\"iniciarCannyPro()\" style=\"padding: 10px 20px; background: #27ae60; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR CANNY</button>\n        <button id=\"btn_off_canny\" onclick=\"detenerTodo()\" style=\"padding: 10px 20px; background: #e74c3c; color: white; border: none; border-radius: 5px; cursor: pointer; margin-left: 10px; display: none;\">üõë APAGAR</button>\n    </div>\n    <p id=\"log_canny_pro\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px;\">Estado: Esperando c√°mara...</p>\n</div>\n\n<script>\n// SISTEMA GLOBAL DE GESTI√ìN DE C√ÅMARA\nif (typeof window.cameraManager === 'undefined') {\n    window.cameraManager = {\n        currentStream: null,\n        currentFilter: null,\n        activeLoop: null\n    };\n}\n\nfunction detenerTodo() {\n    if (window.cameraManager.activeLoop) {\n        window.cameraManager.activeLoop = false;\n    }\n    \n    if (window.cameraManager.currentStream) {\n        window.cameraManager.currentStream.getTracks().forEach(t => t.stop());\n        window.cameraManager.currentStream = null;\n    }\n    \n    // LIMPIAR TODOS LOS CANVAS\n    ['c_canny_pro', 'c_out', 'c_sobel_pro'].forEach(canvasId => {\n        const canvas = document.getElementById(canvasId);\n        if (canvas) {\n            const ctx = canvas.getContext('2d');\n            ctx.clearRect(0, 0, canvas.width, canvas.height);\n            ctx.fillStyle = '#000';\n            ctx.fillRect(0, 0, canvas.width, canvas.height);\n        }\n    });\n    \n    ['btn_off_canny', 'btn_off_sobel', 'b_stop'].forEach(id => {\n        const btn = document.getElementById(id);\n        if (btn) btn.style.display = 'none';\n    });\n    \n    ['btn_on_canny', 'btn_on_sobel', 'b_start'].forEach(id => {\n        const btn = document.getElementById(id);\n        if (btn) btn.style.display = 'inline-block';\n    });\n    \n    ['log_canny_pro', 'log_sobel_pro', 'debug_log'].forEach(id => {\n        const log = document.getElementById(id);\n        if (log) log.innerText = \"C√°mara liberada.\";\n    });\n    \n    window.cameraManager.currentFilter = null;\n}\n\n// Implementaci√≥n REAL de Canny Edge Detection\nfunction applyCannyEdgeDetection(imageData) {\n    const width = imageData.width;\n    const height = imageData.height;\n    const data = imageData.data;\n    \n    // 1. Convertir a escala de grises\n    const gray = new Uint8ClampedArray(width * height);\n    for (let i = 0; i < data.length; i += 4) {\n        const idx = i / 4;\n        gray[idx] = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];\n    }\n    \n    // 2. Suavizado Gaussiano 5x5\n    const smoothed = new Uint8ClampedArray(width * height);\n    const gaussianKernel = [\n        2, 4, 5, 4, 2,\n        4, 9, 12, 9, 4,\n        5, 12, 15, 12, 5,\n        4, 9, 12, 9, 4,\n        2, 4, 5, 4, 2\n    ];\n    const kernelSum = 159;\n    \n    for (let y = 2; y < height - 2; y++) {\n        for (let x = 2; x < width - 2; x++) {\n            let sum = 0;\n            for (let ky = -2; ky <= 2; ky++) {\n                for (let kx = -2; kx <= 2; kx++) {\n                    const idx = (y + ky) * width + (x + kx);\n                    sum += gray[idx] * gaussianKernel[(ky + 2) * 5 + (kx + 2)];\n                }\n            }\n            smoothed[y * width + x] = sum / kernelSum;\n        }\n    }\n    \n    // 3. Calcular gradientes con Sobel\n    const gradX = new Float32Array(width * height);\n    const gradY = new Float32Array(width * height);\n    const magnitude = new Float32Array(width * height);\n    const direction = new Float32Array(width * height);\n    \n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n            \n            // Sobel X\n            const gx = (\n                -smoothed[(y-1)*width + (x-1)] + smoothed[(y-1)*width + (x+1)] +\n                -2*smoothed[y*width + (x-1)] + 2*smoothed[y*width + (x+1)] +\n                -smoothed[(y+1)*width + (x-1)] + smoothed[(y+1)*width + (x+1)]\n            );\n            \n            // Sobel Y\n            const gy = (\n                -smoothed[(y-1)*width + (x-1)] - 2*smoothed[(y-1)*width + x] - smoothed[(y-1)*width + (x+1)] +\n                smoothed[(y+1)*width + (x-1)] + 2*smoothed[(y+1)*width + x] + smoothed[(y+1)*width + (x+1)]\n            );\n            \n            gradX[idx] = gx;\n            gradY[idx] = gy;\n            magnitude[idx] = Math.sqrt(gx * gx + gy * gy);\n            direction[idx] = Math.atan2(gy, gx);\n        }\n    }\n    \n    // 4. Supresi√≥n no-m√°xima (esto hace que Canny sea diferente de Sobel)\n    const suppressed = new Float32Array(width * height);\n    \n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n            const angle = direction[idx] * 180 / Math.PI;\n            const mag = magnitude[idx];\n            \n            let n1 = 0, n2 = 0;\n            \n            // Determinar vecinos seg√∫n la direcci√≥n del gradiente\n            if ((angle >= -22.5 && angle < 22.5) || (angle >= 157.5 || angle < -157.5)) {\n                // Horizontal\n                n1 = magnitude[idx - 1];\n                n2 = magnitude[idx + 1];\n            } else if ((angle >= 22.5 && angle < 67.5) || (angle >= -157.5 && angle < -112.5)) {\n                // Diagonal /\n                n1 = magnitude[(y-1)*width + (x+1)];\n                n2 = magnitude[(y+1)*width + (x-1)];\n            } else if ((angle >= 67.5 && angle < 112.5) || (angle >= -112.5 && angle < -67.5)) {\n                // Vertical\n                n1 = magnitude[(y-1)*width + x];\n                n2 = magnitude[(y+1)*width + x];\n            } else {\n                // Diagonal \\\n                n1 = magnitude[(y-1)*width + (x-1)];\n                n2 = magnitude[(y+1)*width + (x+1)];\n            }\n            \n            // Suprimir si no es m√°ximo local\n            if (mag >= n1 && mag >= n2) {\n                suppressed[idx] = mag;\n            } else {\n                suppressed[idx] = 0;\n            }\n        }\n    }\n    \n    // 5. Umbralizaci√≥n con hist√©resis (doble umbral + seguimiento de bordes)\n    const lowThreshold = 30;\n    const highThreshold = 90;\n    const edges = new Uint8ClampedArray(width * height);\n    \n    // Marcar p√≠xeles fuertes\n    for (let i = 0; i < suppressed.length; i++) {\n        if (suppressed[i] >= highThreshold) {\n            edges[i] = 255; // Borde fuerte\n        } else if (suppressed[i] >= lowThreshold) {\n            edges[i] = 128; // Borde d√©bil (candidato)\n        } else {\n            edges[i] = 0;\n        }\n    }\n    \n    // Seguimiento de bordes (conectar bordes d√©biles a fuertes)\n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n            \n            if (edges[idx] === 128) { // Borde d√©bil\n                // Verificar si est√° conectado a un borde fuerte\n                let connected = false;\n                for (let dy = -1; dy <= 1; dy++) {\n                    for (let dx = -1; dx <= 1; dx++) {\n                        if (edges[(y+dy)*width + (x+dx)] === 255) {\n                            connected = true;\n                            break;\n                        }\n                    }\n                    if (connected) break;\n                }\n                \n                edges[idx] = connected ? 255 : 0;\n            }\n        }\n    }\n    \n    // Convertir a ImageData\n    const output = new ImageData(width, height);\n    for (let i = 0; i < edges.length; i++) {\n        output.data[i * 4] = edges[i];\n        output.data[i * 4 + 1] = edges[i];\n        output.data[i * 4 + 2] = edges[i];\n        output.data[i * 4 + 3] = 255;\n    }\n    \n    return output;\n}\n\nasync function iniciarCannyPro() {\n    const log = document.getElementById('log_canny_pro');\n    \n    detenerTodo();\n    \n    try {\n        log.innerText = \"üì∑ Solicitando c√°mara...\";\n        \n        const stream = await navigator.mediaDevices.getUserMedia({ \n            video: { width: 640, height: 480, facingMode: 'user' } \n        });\n        \n        window.cameraManager.currentStream = stream;\n        window.cameraManager.currentFilter = 'canny';\n        \n        const v = document.getElementById('v_canny_pro');\n        const canvas = document.getElementById('c_canny_pro');\n        const ctx = canvas.getContext('2d');\n        \n        v.srcObject = stream;\n        await v.play();\n        \n        await new Promise(resolve => setTimeout(resolve, 500));\n        \n        document.getElementById('btn_on_canny').style.display = 'none';\n        document.getElementById('btn_off_canny').style.display = 'inline-block';\n        log.innerText = \"‚úÖ Detecci√≥n de bordes Canny activa\";\n        \n        window.cameraManager.activeLoop = true;\n        let frameCount = 0;\n        \n        function processFrame() {\n            if (!window.cameraManager.activeLoop || window.cameraManager.currentFilter !== 'canny') {\n                return;\n            }\n            \n            try {\n                ctx.drawImage(v, 0, 0, canvas.width, canvas.height);\n                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n                \n                // Aplicar CANNY REAL\n                const edges = applyCannyEdgeDetection(imageData);\n                \n                ctx.putImageData(edges, 0, 0);\n                \n                frameCount++;\n                if (frameCount % 30 === 0) {\n                    log.innerText = \"‚úÖ Canny activo - Frames: \" + frameCount;\n                }\n                \n                requestAnimationFrame(processFrame);\n                \n            } catch (e) {\n                console.error('Error:', e);\n                log.innerText = \"‚ùå Error: \" + e.message;\n            }\n        }\n        \n        processFrame();\n        \n    } catch (e) {\n        log.innerText = \"‚ùå Error: \" + e.message;\n        console.error(e);\n    }\n}\n</script>",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h3>M√©todo Canny Edge(Derivadas y Bordes)</h3>\n    <video id=\"v_canny_pro\" width=\"640\" height=\"480\" style=\"display:none\" playsinline></video>\n    <canvas id=\"c_canny_pro\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #27ae60; border-radius: 10px;\"></canvas>\n    <div style=\"margin-top: 15px;\">\n        <button id=\"btn_on_canny\" onclick=\"iniciarCannyPro()\" style=\"padding: 10px 20px; background: #27ae60; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR CANNY</button>\n        <button id=\"btn_off_canny\" onclick=\"detenerTodo()\" style=\"padding: 10px 20px; background: #e74c3c; color: white; border: none; border-radius: 5px; cursor: pointer; margin-left: 10px; display: none;\">üõë APAGAR</button>\n    </div>\n    <p id=\"log_canny_pro\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px;\">Estado: Esperando c√°mara...</p>\n</div>\n\n<script>\n// SISTEMA GLOBAL DE GESTI√ìN DE C√ÅMARA\nif (typeof window.cameraManager === 'undefined') {\n    window.cameraManager = {\n        currentStream: null,\n        currentFilter: null,\n        activeLoop: null\n    };\n}\n\nfunction detenerTodo() {\n    if (window.cameraManager.activeLoop) {\n        window.cameraManager.activeLoop = false;\n    }\n\n    if (window.cameraManager.currentStream) {\n        window.cameraManager.currentStream.getTracks().forEach(t => t.stop());\n        window.cameraManager.currentStream = null;\n    }\n\n    // LIMPIAR TODOS LOS CANVAS\n    ['c_canny_pro', 'c_out', 'c_sobel_pro'].forEach(canvasId => {\n        const canvas = document.getElementById(canvasId);\n        if (canvas) {\n            const ctx = canvas.getContext('2d');\n            ctx.clearRect(0, 0, canvas.width, canvas.height);\n            ctx.fillStyle = '#000';\n            ctx.fillRect(0, 0, canvas.width, canvas.height);\n        }\n    });\n\n    ['btn_off_canny', 'btn_off_sobel', 'b_stop'].forEach(id => {\n        const btn = document.getElementById(id);\n        if (btn) btn.style.display = 'none';\n    });\n\n    ['btn_on_canny', 'btn_on_sobel', 'b_start'].forEach(id => {\n        const btn = document.getElementById(id);\n        if (btn) btn.style.display = 'inline-block';\n    });\n\n    ['log_canny_pro', 'log_sobel_pro', 'debug_log'].forEach(id => {\n        const log = document.getElementById(id);\n        if (log) log.innerText = \"C√°mara liberada.\";\n    });\n\n    window.cameraManager.currentFilter = null;\n}\n\n// Implementaci√≥n REAL de Canny Edge Detection\nfunction applyCannyEdgeDetection(imageData) {\n    const width = imageData.width;\n    const height = imageData.height;\n    const data = imageData.data;\n\n    // 1. Convertir a escala de grises\n    const gray = new Uint8ClampedArray(width * height);\n    for (let i = 0; i < data.length; i += 4) {\n        const idx = i / 4;\n        gray[idx] = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];\n    }\n\n    // 2. Suavizado Gaussiano 5x5\n    const smoothed = new Uint8ClampedArray(width * height);\n    const gaussianKernel = [\n        2, 4, 5, 4, 2,\n        4, 9, 12, 9, 4,\n        5, 12, 15, 12, 5,\n        4, 9, 12, 9, 4,\n        2, 4, 5, 4, 2\n    ];\n    const kernelSum = 159;\n\n    for (let y = 2; y < height - 2; y++) {\n        for (let x = 2; x < width - 2; x++) {\n            let sum = 0;\n            for (let ky = -2; ky <= 2; ky++) {\n                for (let kx = -2; kx <= 2; kx++) {\n                    const idx = (y + ky) * width + (x + kx);\n                    sum += gray[idx] * gaussianKernel[(ky + 2) * 5 + (kx + 2)];\n                }\n            }\n            smoothed[y * width + x] = sum / kernelSum;\n        }\n    }\n\n    // 3. Calcular gradientes con Sobel\n    const gradX = new Float32Array(width * height);\n    const gradY = new Float32Array(width * height);\n    const magnitude = new Float32Array(width * height);\n    const direction = new Float32Array(width * height);\n\n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n\n            // Sobel X\n            const gx = (\n                -smoothed[(y-1)*width + (x-1)] + smoothed[(y-1)*width + (x+1)] +\n                -2*smoothed[y*width + (x-1)] + 2*smoothed[y*width + (x+1)] +\n                -smoothed[(y+1)*width + (x-1)] + smoothed[(y+1)*width + (x+1)]\n            );\n\n            // Sobel Y\n            const gy = (\n                -smoothed[(y-1)*width + (x-1)] - 2*smoothed[(y-1)*width + x] - smoothed[(y-1)*width + (x+1)] +\n                smoothed[(y+1)*width + (x-1)] + 2*smoothed[(y+1)*width + x] + smoothed[(y+1)*width + (x+1)]\n            );\n\n            gradX[idx] = gx;\n            gradY[idx] = gy;\n            magnitude[idx] = Math.sqrt(gx * gx + gy * gy);\n            direction[idx] = Math.atan2(gy, gx);\n        }\n    }\n\n    // 4. Supresi√≥n no-m√°xima (esto hace que Canny sea diferente de Sobel)\n    const suppressed = new Float32Array(width * height);\n\n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n            const angle = direction[idx] * 180 / Math.PI;\n            const mag = magnitude[idx];\n\n            let n1 = 0, n2 = 0;\n\n            // Determinar vecinos seg√∫n la direcci√≥n del gradiente\n            if ((angle >= -22.5 && angle < 22.5) || (angle >= 157.5 || angle < -157.5)) {\n                // Horizontal\n                n1 = magnitude[idx - 1];\n                n2 = magnitude[idx + 1];\n            } else if ((angle >= 22.5 && angle < 67.5) || (angle >= -157.5 && angle < -112.5)) {\n                // Diagonal /\n                n1 = magnitude[(y-1)*width + (x+1)];\n                n2 = magnitude[(y+1)*width + (x-1)];\n            } else if ((angle >= 67.5 && angle < 112.5) || (angle >= -112.5 && angle < -67.5)) {\n                // Vertical\n                n1 = magnitude[(y-1)*width + x];\n                n2 = magnitude[(y+1)*width + x];\n            } else {\n                // Diagonal \\\n                n1 = magnitude[(y-1)*width + (x-1)];\n                n2 = magnitude[(y+1)*width + (x+1)];\n            }\n\n            // Suprimir si no es m√°ximo local\n            if (mag >= n1 && mag >= n2) {\n                suppressed[idx] = mag;\n            } else {\n                suppressed[idx] = 0;\n            }\n        }\n    }\n\n    // 5. Umbralizaci√≥n con hist√©resis (doble umbral + seguimiento de bordes)\n    const lowThreshold = 30;\n    const highThreshold = 90;\n    const edges = new Uint8ClampedArray(width * height);\n\n    // Marcar p√≠xeles fuertes\n    for (let i = 0; i < suppressed.length; i++) {\n        if (suppressed[i] >= highThreshold) {\n            edges[i] = 255; // Borde fuerte\n        } else if (suppressed[i] >= lowThreshold) {\n            edges[i] = 128; // Borde d√©bil (candidato)\n        } else {\n            edges[i] = 0;\n        }\n    }\n\n    // Seguimiento de bordes (conectar bordes d√©biles a fuertes)\n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n\n            if (edges[idx] === 128) { // Borde d√©bil\n                // Verificar si est√° conectado a un borde fuerte\n                let connected = false;\n                for (let dy = -1; dy <= 1; dy++) {\n                    for (let dx = -1; dx <= 1; dx++) {\n                        if (edges[(y+dy)*width + (x+dx)] === 255) {\n                            connected = true;\n                            break;\n                        }\n                    }\n                    if (connected) break;\n                }\n\n                edges[idx] = connected ? 255 : 0;\n            }\n        }\n    }\n\n    // Convertir a ImageData\n    const output = new ImageData(width, height);\n    for (let i = 0; i < edges.length; i++) {\n        output.data[i * 4] = edges[i];\n        output.data[i * 4 + 1] = edges[i];\n        output.data[i * 4 + 2] = edges[i];\n        output.data[i * 4 + 3] = 255;\n    }\n\n    return output;\n}\n\nasync function iniciarCannyPro() {\n    const log = document.getElementById('log_canny_pro');\n\n    detenerTodo();\n\n    try {\n        log.innerText = \"üì∑ Solicitando c√°mara...\";\n\n        const stream = await navigator.mediaDevices.getUserMedia({ \n            video: { width: 640, height: 480, facingMode: 'user' } \n        });\n\n        window.cameraManager.currentStream = stream;\n        window.cameraManager.currentFilter = 'canny';\n\n        const v = document.getElementById('v_canny_pro');\n        const canvas = document.getElementById('c_canny_pro');\n        const ctx = canvas.getContext('2d');\n\n        v.srcObject = stream;\n        await v.play();\n\n        await new Promise(resolve => setTimeout(resolve, 500));\n\n        document.getElementById('btn_on_canny').style.display = 'none';\n        document.getElementById('btn_off_canny').style.display = 'inline-block';\n        log.innerText = \"‚úÖ Detecci√≥n de bordes Canny activa\";\n\n        window.cameraManager.activeLoop = true;\n        let frameCount = 0;\n\n        function processFrame() {\n            if (!window.cameraManager.activeLoop || window.cameraManager.currentFilter !== 'canny') {\n                return;\n            }\n\n            try {\n                ctx.drawImage(v, 0, 0, canvas.width, canvas.height);\n                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n\n                // Aplicar CANNY REAL\n                const edges = applyCannyEdgeDetection(imageData);\n\n                ctx.putImageData(edges, 0, 0);\n\n                frameCount++;\n                if (frameCount % 30 === 0) {\n                    log.innerText = \"‚úÖ Canny activo - Frames: \" + frameCount;\n                }\n\n                requestAnimationFrame(processFrame);\n\n            } catch (e) {\n                console.error('Error:', e);\n                log.innerText = \"‚ùå Error: \" + e.message;\n            }\n        }\n\n        processFrame();\n\n    } catch (e) {\n        log.innerText = \"‚ùå Error: \" + e.message;\n        console.error(e);\n    }\n}\n</script>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "id": "243f3e5a-f4d8-4130-bf62-2c3c02c2d39d",
      "cell_type": "markdown",
      "source": "# An√°lisis Matem√°tico: Algoritmo de Canny (Detecci√≥n √ìptima de Bordes)\n\nFinalmente, hemos implementado el algoritmo de **Canny**, considerado el est√°ndar de oro en visi√≥n por computadora. A diferencia de Sobel, que es un operador simple de derivaci√≥n, Canny es un **proceso multi-etapa** dise√±ado para minimizar el error y garantizar que cada borde se detecte una sola vez.\n\nA continuaci√≥n, detallamos la l√≥gica num√©rica de las 4 etapas que ocurren en nuestro c√≥digo `cv.Canny(dst, dst, 50, 150, 3, false)`:\n\n### 1. Reducci√≥n de Ruido (Suavizado Gaussiano)\nEl c√°lculo de derivadas es extremadamente sensible al ruido (p√≠xeles granulosos). Antes de buscar bordes, aplicamos un filtro de suavizado convolucionando la imagen con un **Kernel Gaussiano** de $5 \\times 5$.\n\nMatem√°ticamente, esto equivale a aplicar una distribuci√≥n normal 2D:\n$$\nG(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n$$\nEsto \"desenfoca\" levemente la imagen para eliminar falsos positivos causados por texturas irrelevantes.\n\n### 2. C√°lculo del Gradiente (Operador Sobel)\nAl igual que en el punto anterior, calculamos la magnitud ($G$) y la direcci√≥n ($\\theta$) del gradiente para cada p√≠xel.\n* **Magnitud:** $G = \\sqrt{G_x^2 + G_y^2}$\n* **Direcci√≥n:** $\\theta = \\arctan(\\frac{G_y}{G_x})$\n\nLa direcci√≥n es crucial porque nos dice hacia d√≥nde \"apunta\" el borde (si es vertical, horizontal o diagonal).\n\n### 3. Supresi√≥n de No-M√°ximos (Adelgazamiento)\nEsta es la etapa donde Canny supera a Sobel.\nSobel produce bordes gruesos y difusos. Canny analiza la direcci√≥n del gradiente en cada p√≠xel y verifica si ese p√≠xel es el **m√°ximo local** en esa direcci√≥n.\n* **L√≥gica:** \"Si el p√≠xel vecino en la direcci√≥n del gradiente tiene una intensidad mayor que yo, entonces yo no soy el borde real. Me apago (pongo a 0).\"\n* **Resultado:** Esto convierte las l√≠neas gruesas en curvas de **1 p√≠xel de ancho**, logrando una precisi√≥n sub-p√≠xel.\n\n### 4. Umbralizaci√≥n por Hist√©resis (Doble Umbral)\nAqu√≠ es donde entran los par√°metros num√©ricos `50` y `150` que definimos en el c√≥digo. Canny clasifica los p√≠xeles en 3 categor√≠as:\n\n1.  **Fuertes ($> 150$):** Son bordes definitivos. Se mantienen.\n2.  **D√©biles ($50 < x < 150$):** Son dudosos.\n3.  **No-Bordes ($< 50$):** Se descartan inmediatamente.\n\n**La Hist√©resis (L√≥gica de Conectividad):**\nPara decidir qu√© hacer con los p√≠xeles \"D√©biles\", Canny aplica un an√°lisis topol√≥gico:\n* Si un p√≠xel d√©bil est√° conectado a uno fuerte, se \"contagia\" y se vuelve fuerte (es parte del borde).\n* Si est√° aislado o solo conectado a otros d√©biles, se descarta (es ruido).\n\nEsta l√≥gica matem√°tica nos permite detectar contornos completos y limpios, incluso si la iluminaci√≥n no es uniforme, superando las limitaciones de los operadores lineales simples.\n\n\n### 7. ¬øEl algoritmo Canny Edge Detection utiliza derivadas?\n[cite_start]**S√≠.** En el contexto de una imagen, un borde se define matem√°ticamente como un cambio brusco en la intensidad de los p√≠xeles[cite: 34]. [cite_start]El algoritmo de Canny busca los puntos donde la primera derivada de la funci√≥n de intensidad de la imagen alcanza un m√°ximo local (es decir, donde el gradiente es m√°s pronunciado)[cite: 35].\n\n### 8. ¬øEn qu√© forma el algoritmo Canny Edge utiliza las diferencias finitas en su c√°lculo?\n[cite_start]Dado que una imagen digital es una matriz discreta de p√≠xeles y no una funci√≥n continua, no es posible calcular derivadas anal√≠ticas[cite: 38]. [cite_start]El algoritmo utiliza **Diferencias Finitas** para aproximar el gradiente[cite: 39]. [cite_start]Se aplican n√∫cleos de convoluci√≥n (como el operador Sobel) que realizan restas ponderadas entre p√≠xeles vecinos (ej. $f(x+1)-f(x-1)$) para estimar la tasa de cambio (derivada) en las direcciones horizontal y vertical[cite: 39].\n\n### 9. Algoritmos para detectar bordes\n[cite_start]Existen diversos operadores basados en el c√°lculo del gradiente a trav√©s de diferencias finitas[cite: 41]:\n* [cite_start]Operador Sobel [cite: 42]\n* [cite_start]Operador Prewitt [cite: 43]\n* [cite_start]Operador Roberts [cite: 44]\n* [cite_start]Laplaciano de Gaussiana (LOG) [cite: 45]\n* [cite_start]Algoritmo de Canny [cite: 46]\n\n### 10. ¬øPara qu√© sirve el algoritmo de Sobel?\n[cite_start]El operador Sobel sirve para calcular una aproximaci√≥n del gradiente de intensidad de una imagen[cite: 48]. [cite_start]Se utiliza para detectar bordes resaltando las regiones de alta frecuencia espacial[cite: 49]. [cite_start]Es computacionalmente eficiente y efectivo para detectar la orientaci√≥n y magnitud de los bordes simples[cite: 50].\n\n### 11 y 12. ¬øC√≥mo utiliza Sobel las derivadas?\n[cite_start]Calcula la **Primera Derivada discreta** usando m√°scaras de $3\\times3$ para $G_{x}$ (horizontal) y $G_{y}$ (vertical)[cite: 52].\nLa magnitud total se obtiene con:\n[cite_start]$$G=\\sqrt{G_{x}^{2}+G_{y}^{2}}$$ [cite: 53]\n\n### 13. Relaci√≥n de Sobel con diferencias finitas\nLa relaci√≥n es directa. [cite_start]El n√∫cleo aplica una **Diferencia Central** combinada con un suavizado[cite: 55]. [cite_start]Por ejemplo, el kernel `[-1, 0, +1]` es la definici√≥n num√©rica de la primera diferencia finita[cite: 56].\n\n### 14. ¬øSe requiere escala de grises para Sobel?\n[cite_start]**S√≠.** Los algoritmos de detecci√≥n de bordes operan sobre cambios de intensidad (luminosidad), no sobre informaci√≥n crom√°tica[cite: 59]. [cite_start]Convertir la imagen a escala de grises simplifica la entrada de 3 canales (RGB) a 1 canal, reduciendo la complejidad computacional y eliminando el ruido que podr√≠an introducir las variaciones de tono[cite: 60].\n\n### 15. ¬øMindAR es de fuente abierta?\n[cite_start]**S√≠.** MindAR se distribuye bajo la licencia MIT[cite: 62]. [cite_start]Esto significa que es software libre y de c√≥digo abierto, permitiendo su uso, modificaci√≥n y distribuci√≥n tanto para proyectos personales como comerciales sin restricciones significativas[cite: 63].\n\n### 16. ¬øQu√© es MediaPipe Face Mesh de Google?\n[cite_start]MediaPipe Face Mesh es una soluci√≥n de aprendizaje autom√°tico (Machine Learning) desarrollada por Google que permite la estimaci√≥n geom√©trica de rostros en tiempo real[cite: 65]. [cite_start]Es capaz de detectar **468 puntos de referencia (landmarks)** en 3D sobre el rostro humano, funcionando eficientemente incluso en dispositivos m√≥viles sin hardware dedicado[cite: 66].\n\n### 17, 20, 21 y 22. Implementaci√≥n T√©cnica: Face Mesh con Filtros y WebCam\n[cite_start]A continuaci√≥n se presenta el c√≥digo fuente que integra los requerimientos[cite: 76]:\n* [cite_start]**Punto 17:** Carga MediaPipe Face Mesh y dibuja los 468 puntos[cite: 78].\n* [cite_start]**Punto 20:** Solicitud de acceso a webcam[cite: 79].\n* [cite_start]**Punto 21:** Edici√≥n de m√°scara colocando un objeto[cite: 80].\n* [cite_start]**Punto 22:** Filtro en un punto espec√≠fico (nariz)[cite: 81].\n",
      "metadata": {}
    },
    {
      "id": "c8ad0994-3d41-40ba-9e19-2a01b591d38b",
      "cell_type": "code",
      "source": "%%html\n<div id=\"ar_final_box\" style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h2 style=\"color: #3498db;\">PROYECTO FINAL: Filtros AR 3D</h2>\n    \n    <div style=\"margin-bottom: 10px; display: flex; justify-content: center; gap: 5px; flex-wrap: wrap;\">\n        <button onclick=\"setF(0)\">‚ùå Quitar</button>\n        <button onclick=\"setF(1)\">üî¥ Nariz Roja</button>\n        <button onclick=\"setF(2)\">ü§† Sombrero</button>\n        <button onclick=\"setF(3)\">üòé Lentes</button>\n        <button onclick=\"setF(4)\">üëë Corona</button>\n    </div>\n\n    <div style=\"margin-bottom: 15px;\">\n        <button id=\"m_btn\" onclick=\"togM()\" style=\"padding: 8px 15px; background: #8e44ad; color: white; border: none; border-radius: 5px; cursor: pointer;\">Ocultar Malla Verde</button>\n    </div>\n\n    <div style=\"position: relative; display: inline-block;\">\n        <video id=\"v_src\" style=\"display:none\" playsinline></video>\n        <canvas id=\"c_out\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #444; border-radius: 10px;\"></canvas>\n    </div>\n    \n    <div style=\"margin-top: 15px;\">\n        <button id=\"b_start\" onclick=\"runAr()\" style=\"padding: 15px 30px; background: #27ae60; color: white; border: none; border-radius: 10px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR FILTROS AR</button>\n        <button onclick=\"detenerTodo()\" style=\"padding: 15px 30px; background: #e74c3c; color: white; border: none; border-radius: 10px; cursor: pointer; margin-left: 10px; display: none;\" id=\"b_stop\">üõë APAGAR</button>\n        <p id=\"debug_log\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px; background: #000; padding: 5px;\">Estado: Esperando clic...</p>\n    </div>\n</div>\n\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js\" crossorigin=\"anonymous\"></script>\n\n<script>\nvar vid_el = document.getElementById('v_src');\nvar can_el = document.getElementById('c_out');\nvar ctx_el = can_el.getContext('2d');\nvar log_el = document.getElementById('debug_log');\n\nvar show_m = true;\nvar filter_id = 0;\nvar arCamera = null;\n\nfunction setF(n) {\n    filter_id = n;\n    log_el.innerText = n > 0 ? \"Filtro \" + n + \" activado ‚úì\" : \"Filtro removido\";\n}\n\nfunction togM() {\n    show_m = !show_m;\n    document.getElementById('m_btn').innerText = show_m ? \"Ocultar Malla Verde\" : \"Mostrar Malla Verde\";\n}\n\n// FUNCIONES PARA DIBUJAR FILTROS\nfunction drawClownNose(ctx, x, y, size) {\n    ctx.save();\n    ctx.shadowColor = 'rgba(0,0,0,0.4)';\n    ctx.shadowBlur = 25;\n    ctx.shadowOffsetX = 15;\n    ctx.shadowOffsetY = 15;\n    \n    const gradient = ctx.createRadialGradient(x - size*0.2, y - size*0.2, 0, x, y, size*0.6);\n    gradient.addColorStop(0, '#ff6b6b');\n    gradient.addColorStop(0.5, '#ee4444');\n    gradient.addColorStop(1, '#cc2222');\n    \n    ctx.fillStyle = gradient;\n    ctx.beginPath();\n    ctx.arc(x, y, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    \n    ctx.shadowColor = 'transparent';\n    const highlightGrad = ctx.createRadialGradient(x - size*0.15, y - size*0.15, 0, x - size*0.15, y - size*0.15, size*0.25);\n    highlightGrad.addColorStop(0, 'rgba(255,255,255,0.9)');\n    highlightGrad.addColorStop(1, 'rgba(255,255,255,0)');\n    ctx.fillStyle = highlightGrad;\n    ctx.beginPath();\n    ctx.arc(x - size*0.15, y - size*0.15, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    \n    ctx.fillStyle = 'rgba(255,255,255,0.6)';\n    ctx.beginPath();\n    ctx.arc(x + size*0.1, y + size*0.15, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.restore();\n}\n\nfunction drawHat(ctx, x, y, size) {\n    ctx.save();\n    ctx.fillStyle = '#8B4513';\n    ctx.strokeStyle = '#654321';\n    ctx.lineWidth = 3;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 15;\n    \n    ctx.beginPath();\n    ctx.ellipse(x, y, size*0.8, size*0.25, 0, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n    \n    ctx.fillStyle = '#A0522D';\n    ctx.beginPath();\n    ctx.moveTo(x - size*0.4, y);\n    ctx.lineTo(x - size*0.35, y - size*0.8);\n    ctx.lineTo(x + size*0.35, y - size*0.8);\n    ctx.lineTo(x + size*0.4, y);\n    ctx.closePath();\n    ctx.fill();\n    ctx.stroke();\n    \n    ctx.fillStyle = '#FFD700';\n    ctx.fillRect(x - size*0.35, y - size*0.3, size*0.7, size*0.15);\n    ctx.restore();\n}\n\nfunction drawGlasses(ctx, x, y, size) {\n    ctx.save();\n    ctx.strokeStyle = '#000000';\n    ctx.lineWidth = 4;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 10;\n    \n    ctx.fillStyle = 'rgba(0,0,0,0.3)';\n    ctx.beginPath();\n    ctx.arc(x - size*0.35, y, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n    \n    ctx.beginPath();\n    ctx.arc(x + size*0.35, y, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n    \n    ctx.beginPath();\n    ctx.moveTo(x - size*0.1, y);\n    ctx.lineTo(x + size*0.1, y);\n    ctx.stroke();\n    \n    ctx.fillStyle = 'rgba(255,255,255,0.6)';\n    ctx.beginPath();\n    ctx.arc(x - size*0.42, y - size*0.08, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.beginPath();\n    ctx.arc(x + size*0.28, y - size*0.08, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.restore();\n}\n\nfunction drawCrown(ctx, x, y, size) {\n    ctx.save();\n    ctx.fillStyle = '#FFD700';\n    ctx.strokeStyle = '#FFA500';\n    ctx.lineWidth = 3;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 15;\n    \n    ctx.beginPath();\n    ctx.moveTo(x - size*0.5, y);\n    ctx.lineTo(x - size*0.4, y - size*0.4);\n    ctx.lineTo(x - size*0.25, y - size*0.2);\n    ctx.lineTo(x, y - size*0.5);\n    ctx.lineTo(x + size*0.25, y - size*0.2);\n    ctx.lineTo(x + size*0.4, y - size*0.4);\n    ctx.lineTo(x + size*0.5, y);\n    ctx.closePath();\n    ctx.fill();\n    ctx.stroke();\n    \n    const jewels = [\n        {x: x - size*0.4, y: y - size*0.4, c: '#ff0000'},\n        {x: x - size*0.25, y: y - size*0.2, c: '#00ff00'},\n        {x: x, y: y - size*0.5, c: '#ff0000'},\n        {x: x + size*0.25, y: y - size*0.2, c: '#0000ff'},\n        {x: x + size*0.4, y: y - size*0.4, c: '#ff00ff'}\n    ];\n    \n    jewels.forEach(j => {\n        ctx.fillStyle = j.c;\n        ctx.beginPath();\n        ctx.arc(j.x, j.y, size*0.05, 0, Math.PI * 2);\n        ctx.fill();\n    });\n    ctx.restore();\n}\n\nasync function runAr() {\n    log_el.innerText = \"Paso 1: Solicitando c√°mara...\";\n    \n    // Detener otros filtros\n    detenerTodo();\n    \n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });\n        window.cameraManager.currentStream = stream;\n        window.cameraManager.currentFilter = 'ar';\n        \n        vid_el.srcObject = stream;\n        await vid_el.play();\n        \n        document.getElementById('b_start').style.display = 'none';\n        document.getElementById('b_stop').style.display = 'inline-block';\n        \n        log_el.innerText = \"Paso 2: C√°mara activa. Cargando IA...\";\n        setTimeout(startIA, 500);\n    } catch (e) {\n        log_el.innerText = \"ERROR: No se pudo abrir la c√°mara. ¬øDiste permiso?\";\n        console.error(e);\n    }\n}\n\nfunction startIA() {\n    try {\n        const mesh = new FaceMesh({\n            locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`\n        });\n        \n        mesh.setOptions({ \n            maxNumFaces: 1, \n            refineLandmarks: true, \n            minDetectionConfidence: 0.5,\n            minTrackingConfidence: 0.5\n        });\n        \n        mesh.onResults((res) => {\n            if (window.cameraManager.currentFilter !== 'ar') return;\n            \n            ctx_el.save();\n            ctx_el.clearRect(0, 0, can_el.width, can_el.height);\n            ctx_el.drawImage(res.image, 0, 0, can_el.width, can_el.height);\n            \n            if (res.multiFaceLandmarks && res.multiFaceLandmarks.length > 0) {\n                const face = res.multiFaceLandmarks[0];\n                \n                if (show_m) {\n                    drawConnectors(ctx_el, face, FACEMESH_TESSELATION, {color: '#00FF0050', lineWidth: 1});\n                }\n\n                const faceW = Math.abs(face[454].x - face[234].x) * can_el.width;\n                \n                if (filter_id === 1) {\n                    const nose = face[1];\n                    drawClownNose(ctx_el, nose.x * can_el.width, nose.y * can_el.height, faceW * 0.15);\n                } \n                else if (filter_id === 2) {\n                    const top = face[10];\n                    drawHat(ctx_el, top.x * can_el.width, (top.y * can_el.height) - faceW*0.6, faceW * 0.8);\n                }\n                else if (filter_id === 3) {\n                    const eyes = face[168];\n                    drawGlasses(ctx_el, eyes.x * can_el.width, eyes.y * can_el.height, faceW);\n                }\n                else if (filter_id === 4) {\n                    const top = face[10];\n                    drawCrown(ctx_el, top.x * can_el.width, (top.y * can_el.height) - faceW*0.5, faceW * 0.6);\n                }\n            }\n            ctx_el.restore();\n        });\n\n        arCamera = new Camera(vid_el, {\n            onFrame: async () => {\n                if (window.cameraManager.currentFilter === 'ar') {\n                    await mesh.send({image: vid_el});\n                }\n            },\n            width: 640, \n            height: 480\n        });\n        \n        arCamera.start();\n        log_el.innerText = \"‚úÖ ¬°Todo listo! Selecciona un filtro\";\n        \n    } catch (err) {\n        log_el.innerText = \"ERROR de IA: \" + err.message;\n        console.error(err);\n    }\n}\n</script>",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div id=\"ar_final_box\" style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h2 style=\"color: #3498db;\">PROYECTO FINAL: Filtros AR 3D</h2>\n\n    <div style=\"margin-bottom: 10px; display: flex; justify-content: center; gap: 5px; flex-wrap: wrap;\">\n        <button onclick=\"setF(0)\">‚ùå Quitar</button>\n        <button onclick=\"setF(1)\">üî¥ Nariz Roja</button>\n        <button onclick=\"setF(2)\">ü§† Sombrero</button>\n        <button onclick=\"setF(3)\">üòé Lentes</button>\n        <button onclick=\"setF(4)\">üëë Corona</button>\n    </div>\n\n    <div style=\"margin-bottom: 15px;\">\n        <button id=\"m_btn\" onclick=\"togM()\" style=\"padding: 8px 15px; background: #8e44ad; color: white; border: none; border-radius: 5px; cursor: pointer;\">Ocultar Malla Verde</button>\n    </div>\n\n    <div style=\"position: relative; display: inline-block;\">\n        <video id=\"v_src\" style=\"display:none\" playsinline></video>\n        <canvas id=\"c_out\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #444; border-radius: 10px;\"></canvas>\n    </div>\n\n    <div style=\"margin-top: 15px;\">\n        <button id=\"b_start\" onclick=\"runAr()\" style=\"padding: 15px 30px; background: #27ae60; color: white; border: none; border-radius: 10px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR C√ÅMARA</button>\n        <p id=\"debug_log\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px; background: #000; padding: 5px;\">Estado: Esperando clic...</p>\n    </div>\n</div>\n\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js\" crossorigin=\"anonymous\"></script>\n\n<script>\nvar vid_el = document.getElementById('v_src');\nvar can_el = document.getElementById('c_out');\nvar ctx_el = can_el.getContext('2d');\nvar log_el = document.getElementById('debug_log');\n\nvar show_m = true;\nvar filter_id = 0;\n\nfunction setF(n) {\n    filter_id = n;\n    log_el.innerText = n > 0 ? \"Filtro \" + n + \" activado ‚úì\" : \"Filtro removido\";\n}\n\nfunction togM() {\n    show_m = !show_m;\n    document.getElementById('m_btn').innerText = show_m ? \"Ocultar Malla Verde\" : \"Mostrar Malla Verde\";\n}\n\n// FUNCIONES PARA DIBUJAR FILTROS (sin im√°genes externas)\n//1. NARIZ DE PAYASO ROJA con brillo realista\nfunction drawClownNose(ctx, x, y, size) {\n    ctx.save();\n\n    // Sombra\n    ctx.shadowColor = 'rgba(0,0,0,0.4)';\n    ctx.shadowBlur = 25;\n    ctx.shadowOffsetX = 15;\n    ctx.shadowOffsetY = 15;\n\n    // Gradiente principal rojo\n    const gradient = ctx.createRadialGradient(x - size*0.2, y - size*0.2, 0, x, y, size*0.6);\n    gradient.addColorStop(0, '#ff6b6b');\n    gradient.addColorStop(0.5, '#ee4444');\n    gradient.addColorStop(1, '#cc2222');\n\n    ctx.fillStyle = gradient;\n    ctx.beginPath();\n    ctx.arc(x, y, size*0.25, 0, Math.PI * 8);\n    ctx.fill();\n\n    // Brillo superior izquierdo (grande)\n    ctx.shadowColor = 'transparent';\n    const highlightGrad = ctx.createRadialGradient(x - size*0.15, y - size*0.15, 0, x - size*0.15, y - size*0.15, size*0.25);\n    highlightGrad.addColorStop(0, 'rgba(255,255,255,0.9)');\n    highlightGrad.addColorStop(1, 'rgba(255,255,255,0)');\n    ctx.fillStyle = highlightGrad;\n    ctx.beginPath();\n    ctx.arc(x - size*0.15, y - size*0.15, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n\n    // Brillo peque√±o extra\n    ctx.fillStyle = 'rgba(255,255,255,0.6)';\n    ctx.beginPath();\n    ctx.arc(x + size*0.1, y + size*0.15, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n\n    ctx.restore();\n}\n\nfunction drawHat(ctx, x, y, size) {\n    ctx.save();\n    ctx.fillStyle = '#8B4513';\n    ctx.strokeStyle = '#654321';\n    ctx.lineWidth = 3;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 15;\n\n    // Ala del sombrero\n    ctx.beginPath();\n    ctx.ellipse(x, y, size*0.8, size*0.25, 0, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n\n    // Copa del sombrero\n    ctx.fillStyle = '#A0522D';\n    ctx.beginPath();\n    ctx.moveTo(x - size*0.4, y);\n    ctx.lineTo(x - size*0.35, y - size*0.8);\n    ctx.lineTo(x + size*0.35, y - size*0.8);\n    ctx.lineTo(x + size*0.4, y);\n    ctx.closePath();\n    ctx.fill();\n    ctx.stroke();\n\n    // Banda\n    ctx.fillStyle = '#FFD700';\n    ctx.fillRect(x - size*0.35, y - size*0.3, size*0.7, size*0.15);\n    ctx.restore();\n}\n\nfunction drawGlasses(ctx, x, y, size) {\n    ctx.save();\n    ctx.strokeStyle = '#000000';\n    ctx.lineWidth = 4;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 10;\n\n    // Lente izquierdo\n    ctx.fillStyle = 'rgba(0,0,0,0.3)';\n    ctx.beginPath();\n    ctx.arc(x - size*0.35, y, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n\n    // Lente derecho\n    ctx.beginPath();\n    ctx.arc(x + size*0.35, y, size*0.25, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.stroke();\n\n    // Puente\n    ctx.beginPath();\n    ctx.moveTo(x - size*0.1, y);\n    ctx.lineTo(x + size*0.1, y);\n    ctx.stroke();\n\n    // Brillos\n    ctx.fillStyle = 'rgba(255,255,255,0.6)';\n    ctx.beginPath();\n    ctx.arc(x - size*0.42, y - size*0.08, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.beginPath();\n    ctx.arc(x + size*0.28, y - size*0.08, size*0.08, 0, Math.PI * 2);\n    ctx.fill();\n    ctx.restore();\n}\n\nfunction drawCrown(ctx, x, y, size) {\n    ctx.save();\n    ctx.fillStyle = '#FFD700';\n    ctx.strokeStyle = '#FFA500';\n    ctx.lineWidth = 3;\n    ctx.shadowColor = 'rgba(0,0,0,0.5)';\n    ctx.shadowBlur = 15;\n\n    ctx.beginPath();\n    ctx.moveTo(x - size*0.5, y);\n    ctx.lineTo(x - size*0.4, y - size*0.4);\n    ctx.lineTo(x - size*0.25, y - size*0.2);\n    ctx.lineTo(x, y - size*0.5);\n    ctx.lineTo(x + size*0.25, y - size*0.2);\n    ctx.lineTo(x + size*0.4, y - size*0.4);\n    ctx.lineTo(x + size*0.5, y);\n    ctx.closePath();\n    ctx.fill();\n    ctx.stroke();\n\n    // Joyas\n    const jewels = [\n        {x: x - size*0.4, y: y - size*0.4, c: '#ff0000'},\n        {x: x - size*0.25, y: y - size*0.2, c: '#00ff00'},\n        {x: x, y: y - size*0.5, c: '#ff0000'},\n        {x: x + size*0.25, y: y - size*0.2, c: '#0000ff'},\n        {x: x + size*0.4, y: y - size*0.4, c: '#ff00ff'}\n    ];\n\n    jewels.forEach(j => {\n        ctx.fillStyle = j.c;\n        ctx.beginPath();\n        ctx.arc(j.x, j.y, size*0.05, 0, Math.PI * 2);\n        ctx.fill();\n    });\n    ctx.restore();\n}\n\nasync function runAr() {\n    log_el.innerText = \"Paso 1: Solicitando c√°mara...\";\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });\n        vid_el.srcObject = stream;\n        await vid_el.play();\n        log_el.innerText = \"Paso 2: C√°mara activa. Cargando IA...\";\n        setTimeout(startIA, 500);\n    } catch (e) {\n        log_el.innerText = \"ERROR: No se pudo abrir la c√°mara. ¬øDiste permiso?\";\n        console.error(e);\n    }\n}\n\nfunction startIA() {\n    try {\n        const mesh = new FaceMesh({\n            locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`\n        });\n\n        mesh.setOptions({ \n            maxNumFaces: 1, \n            refineLandmarks: true, \n            minDetectionConfidence: 0.5,\n            minTrackingConfidence: 0.5\n        });\n\n        mesh.onResults((res) => {\n            ctx_el.save();\n            ctx_el.clearRect(0, 0, can_el.width, can_el.height);\n            ctx_el.drawImage(res.image, 0, 0, can_el.width, can_el.height);\n\n            if (res.multiFaceLandmarks && res.multiFaceLandmarks.length > 0) {\n                const face = res.multiFaceLandmarks[0];\n\n                if (show_m) {\n                    drawConnectors(ctx_el, face, FACEMESH_TESSELATION, {color: '#00FF0050', lineWidth: 1});\n                }\n\n                // Calcular ancho de cara\n                const faceW = Math.abs(face[454].x - face[234].x) * can_el.width;\n\n                // Dibujar filtros\n                if (filter_id === 1) {\n                    const nose = face[1];\n                    drawNose(ctx_el, nose.x * can_el.width, nose.y * can_el.height, faceW * 0.15);\n                } \n                else if (filter_id === 2) {\n                    const top = face[10];\n                    drawHat(ctx_el, top.x * can_el.width, (top.y * can_el.height) - faceW*0.6, faceW * 0.8);\n                }\n                else if (filter_id === 3) {\n                    const eyes = face[168];\n                    drawGlasses(ctx_el, eyes.x * can_el.width, eyes.y * can_el.height, faceW);\n                }\n                else if (filter_id === 4) {\n                    const top = face[10];\n                    drawCrown(ctx_el, top.x * can_el.width, (top.y * can_el.height) - faceW*0.5, faceW * 0.6);\n                }\n            }\n            ctx_el.restore();\n        });\n\n        const cam = new Camera(vid_el, {\n            onFrame: async () => { \n                await mesh.send({image: vid_el}); \n            },\n            width: 640, \n            height: 480\n        });\n\n        cam.start();\n        log_el.innerText = \"‚úÖ ¬°Todo listo! Selecciona un filtro\";\n\n    } catch (err) {\n        log_el.innerText = \"ERROR de IA: \" + err.message;\n        console.error(err);\n    }\n}\n</script>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "id": "a38d9007-9435-4b23-934d-32190095a305",
      "cell_type": "markdown",
      "source": "# An√°lisis Matem√°tico y L√≥gico de Nuestro Algoritmo AR\n\nEn este proyecto, nuestro equipo no ha utilizado im√°genes est√°ticas pre-cargadas para los filtros. En su lugar, hemos desarrollado un motor de renderizado basado en **Geometr√≠a Computacional** y **√Ålgebra Lineal**. A continuaci√≥n, explicamos la l√≥gica matem√°tica interna que permite que los objetos se adapten al rostro en tiempo real.\n\n### 1. Transformaci√≥n de Espacios Vectoriales (Mapeo Lineal)\nEl modelo de Inteligencia Artificial (MediaPipe Face Mesh) nos devuelve una matriz de 468 puntos (landmarks). Sin embargo, estos puntos vienen en un **Espacio Normalizado**, es decir, son valores flotantes entre $0$ y $1$ donde:\n* $(0,0)$ representa la esquina superior izquierda.\n* $(1,1)$ representa la esquina inferior derecha.\n\nPara dibujar en el canvas, hemos aplicado una **Transformaci√≥n Lineal de Escala** para mapear estos valores al **Espacio Cartesiano de P√≠xeles** ($640 \\times 480$).\n\nLa f√≥rmula que hemos implementado para cada punto $P(x,y)$ es:\n\n$$\nP_{pixel} = P_{norm} \\cdot \\vec{S}\n$$\n\nDonde el vector de escala $\\vec{S}$ corresponde a las dimensiones del canvas:\n$$\nx_{pixel} = x_{norm} \\cdot Ancho_{canvas}\n$$\n$$\ny_{pixel} = y_{norm} \\cdot Alto_{canvas}\n$$\n\n> **En nuestro c√≥digo:** Esto se observa cuando pasamos los argumentos a las funciones de dibujo, por ejemplo: `nose.x * can_el.width`.\n\n---\n\n### 2. Escalamiento Din√°mico (Geometr√≠a Proyectiva)\nUno de los retos principales que enfrentamos fue lograr que los lentes o el sombrero cambiaran de tama√±o si el usuario se acerca o aleja de la c√°mara (simulaci√≥n de profundidad $Z$). Como no contamos con un sensor de profundidad real, utilizamos una **referencia m√©trica relativa**.\n\nHemos seleccionado dos puntos ancla anat√≥micamente estables: los p√≥mulos (Landmarks **#454** y **#234**). Calculamos la magnitud del vector diferencia entre ellos en el eje X para determinar el \"ancho aparente\" de la cara ($W_{cara}$).\n\n$$\nW_{cara} = |x_{454} - x_{234}| \\cdot Ancho_{pixel}\n$$\n\nEste valor $W_{cara}$ se convierte en nuestro escalar base ($k$). Todas las figuras geom√©tricas se dibujan como una funci√≥n de $k$:\n* Radio de la nariz = $0.15 \\cdot k$\n* Ancho de los lentes = $1.0 \\cdot k$\n\nDe esta forma, mantenemos la **proporcionalidad** euclidiana sin importar la distancia de la c√°mara.\n\n---\n\n### 3. Construcci√≥n de Primitivas Geom√©tricas\nEn lugar de pegar im√°genes (bitmaps), hemos utilizado ecuaciones geom√©tricas para rasterizar los objetos p√≠xel por p√≠xel.\n\n#### A. La Nariz (Gradientes Radiales)\nPara la nariz, no dibujamos un c√≠rculo plano. Para simular volumen (3D), implementamos una funci√≥n de **Gradiente Radial** $G(r)$. Matem√°ticamente, interpolamos el color desde un centro desplazado $(x - \\Delta, y - \\Delta)$ hacia el radio exterior $r$.\n\nLa ecuaci√≥n base es la del c√≠rculo:\n$$\n(x - h)^2 + (y - k)^2 = r^2\n$$\n\nAl desplazar el foco del gradiente hacia la esquina superior izquierda, simulamos una fuente de luz, creando un efecto de esfericidad (especularidad) mediante el c√°lculo de la intensidad de color $I$ en funci√≥n del radio.\n\n#### B. La Corona y el Sombrero (Pol√≠gonos y Traslaci√≥n)\nPara estos objetos, definimos pol√≠gonos irregulares conectando una secuencia de v√©rtices $V_1, V_2, \\dots, V_n$.\n\nEl desaf√≠o matem√°tico aqu√≠ es la **Traslaci√≥n de Vectores**. Si dibuj√°ramos la corona en las coordenadas de la frente (Landmark #10), quedar√≠a *dentro* de la cabeza. Para corregirlo, aplicamos un vector de desplazamiento negativo en el eje Y (recordando que en computaci√≥n gr√°fica, el eje Y positivo va hacia abajo).\n\n$$\nP_{objeto} = P_{frente} + \\vec{v}_{desplazamiento}\n$$\n\nDonde $\\vec{v}_{desplazamiento} = (0, -0.6 \\cdot W_{cara})$. Esto eleva el objeto proporcionalmente al tama√±o de la cabeza detectada.\n\n---\n\n### 4. Topolog√≠a de Malla (Teor√≠a de Grafos)\nFinalmente, la \"Malla Verde\" que visualizamos es una representaci√≥n directa de la topolog√≠a del grafo que utiliza la red neuronal.\n* **V√©rtices ($V$):** Los 468 puntos detectados.\n* **Aristas ($E$):** Las conexiones predefinidas (teselaci√≥n) que unen los puntos para formar tri√°ngulos.\n\nHemos utilizado la funci√≥n `drawConnectors` que recorre la matriz de adyacencia del grafo y renderiza las l√≠neas que conectan los nodos $V_i$ y $V_j$, permitiendo visualizar la geometr√≠a subyacente que la computadora \"ve\" en el rostro.\n\n\n### 18. ¬øMediaPipe utiliza Sobel?\n[cite_start]**No directamente.** MediaPipe utiliza Redes Neuronales Convolucionales (CNN)[cite: 158]. [cite_start]A diferencia del algoritmo Sobel, que utiliza f√≥rmulas matem√°ticas fijas (kernels predefinidos) para buscar bordes, MediaPipe utiliza modelos entrenados con millones de im√°genes para aprender a identificar patrones complejos como ojos, labios y contornos faciales, independientemente de los bordes simples[cite: 158].\n\n### 19. ¬øQu√© son las redes neuronales convolucionales (CNN)?\n[cite_start]Son un tipo de arquitectura de Deep Learning dise√±ada espec√≠ficamente para procesar datos con estructura de cuadr√≠cula, como las im√°genes[cite: 160]. [cite_start]\n\n[Image of convolutional neural network architecture]\n Utilizan capas de \"convoluci√≥n\" que funcionan como filtros aprendidos autom√°ticamente[cite: 161]. [cite_start]A diferencia de Sobel (donde el humano define el filtro), una CNN aprende por s√≠ sola qu√© filtros aplicar para detectar desde l√≠neas simples hasta formas complejas como una cara humana[cite: 161].\n\n### 23. Escribir el mismo concepto pero usando Sobel\n[cite_start]Implementaci√≥n de procesamiento de video en tiempo real utilizando el operador Sobel para detecci√≥n de bordes mediante OpenCV.js[cite: 163].",
      "metadata": {}
    },
    {
      "id": "301c4af0-d3da-4be4-a19f-ed6b4ce79c53",
      "cell_type": "code",
      "source": "%%html\n<div style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h3>M√©todo Sobel (Gradientes de Intensidad)</h3>\n    <video id=\"v_sobel_pro\" width=\"640\" height=\"480\" style=\"display:none\" playsinline></video>\n    <canvas id=\"c_sobel_pro\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #2980b9; border-radius: 10px;\"></canvas>\n    <div style=\"margin-top: 15px;\">\n        <button id=\"btn_on_sobel\" onclick=\"iniciarSobelPro()\" style=\"padding: 10px 20px; background: #2980b9; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR SOBEL</button>\n        <button id=\"btn_off_sobel\" onclick=\"detenerTodo()\" style=\"padding: 10px 20px; background: #e74c3c; color: white; border: none; border-radius: 5px; cursor: pointer; margin-left: 10px; display: none;\">üõë APAGAR</button>\n    </div>\n    <p id=\"log_sobel_pro\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px;\">Estado: Esperando c√°mara...</p>\n</div>\n\n<script>\n// Implementaci√≥n de Sobel\nfunction applySobelGradients(imageData) {\n    const width = imageData.width;\n    const height = imageData.height;\n    const data = imageData.data;\n    \n    // Convertir a escala de grises\n    const gray = new Uint8ClampedArray(width * height);\n    for (let i = 0; i < data.length; i += 4) {\n        const idx = i / 4;\n        gray[idx] = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];\n    }\n    \n    // Aplicar Sobel\n    const gradX = new Float32Array(width * height);\n    const gradY = new Float32Array(width * height);\n    const magnitude = new Uint8ClampedArray(width * height);\n    \n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n            \n            // Sobel X (detecta bordes verticales)\n            const gx = (\n                -gray[(y-1)*width + (x-1)] + gray[(y-1)*width + (x+1)] +\n                -2*gray[y*width + (x-1)] + 2*gray[y*width + (x+1)] +\n                -gray[(y+1)*width + (x-1)] + gray[(y+1)*width + (x+1)]\n            );\n            \n            // Sobel Y (detecta bordes horizontales)\n            const gy = (\n                -gray[(y-1)*width + (x-1)] - 2*gray[(y-1)*width + x] - gray[(y-1)*width + (x+1)] +\n                gray[(y+1)*width + (x-1)] + 2*gray[(y+1)*width + x] + gray[(y+1)*width + (x+1)]\n            );\n            \n            gradX[idx] = gx;\n            gradY[idx] = gy;\n            \n            // Magnitud del gradiente\n            const mag = Math.sqrt(gx * gx + gy * gy);\n            magnitude[idx] = Math.min(255, mag);\n        }\n    }\n    \n    // Convertir a ImageData\n    const output = new ImageData(width, height);\n    for (let i = 0; i < magnitude.length; i++) {\n        output.data[i * 4] = magnitude[i];\n        output.data[i * 4 + 1] = magnitude[i];\n        output.data[i * 4 + 2] = magnitude[i];\n        output.data[i * 4 + 3] = 255;\n    }\n    \n    return output;\n}\n\nasync function iniciarSobelPro() {\n    const log = document.getElementById('log_sobel_pro');\n    \n    // Detener otros filtros Y limpiar sus canvas\n    detenerTodo();\n    \n    // IMPORTANTE: Limpiar TODOS los canvas antes de empezar\n    ['c_canny_pro', 'c_out', 'c_sobel_pro'].forEach(canvasId => {\n        const canvas = document.getElementById(canvasId);\n        if (canvas) {\n            const ctx = canvas.getContext('2d');\n            ctx.clearRect(0, 0, canvas.width, canvas.height);\n            ctx.fillStyle = '#000';\n            ctx.fillRect(0, 0, canvas.width, canvas.height);\n        }\n    });\n    \n    try {\n        log.innerText = \"üì∑ Solicitando c√°mara...\";\n        \n        const stream = await navigator.mediaDevices.getUserMedia({ \n            video: { width: 640, height: 480, facingMode: 'user' } \n        });\n        \n        window.cameraManager.currentStream = stream;\n        window.cameraManager.currentFilter = 'sobel';\n        \n        const v = document.getElementById('v_sobel_pro');\n        const canvas = document.getElementById('c_sobel_pro');\n        const ctx = canvas.getContext('2d');\n        \n        v.srcObject = stream;\n        await v.play();\n        \n        await new Promise(resolve => setTimeout(resolve, 500));\n        \n        document.getElementById('btn_on_sobel').style.display = 'none';\n        document.getElementById('btn_off_sobel').style.display = 'inline-block';\n        log.innerText = \"‚úÖ Gradientes Sobel activos\";\n        \n        window.cameraManager.activeLoop = true;\n        let frameCount = 0;\n        \n        function processFrame() {\n            if (!window.cameraManager.activeLoop || window.cameraManager.currentFilter !== 'sobel') {\n                return;\n            }\n            \n            try {\n                ctx.drawImage(v, 0, 0, canvas.width, canvas.height);\n                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n                \n                // Aplicar SOBEL\n                const edges = applySobelGradients(imageData);\n                \n                ctx.putImageData(edges, 0, 0);\n                \n                frameCount++;\n                if (frameCount % 30 === 0) {\n                    log.innerText = \"‚úÖ Sobel activo - Frames: \" + frameCount;\n                }\n                \n                requestAnimationFrame(processFrame);\n                \n            } catch (e) {\n                console.error('Error:', e);\n                log.innerText = \"‚ùå Error: \" + e.message;\n            }\n        }\n        \n        processFrame();\n        \n    } catch (e) {\n        log.innerText = \"‚ùå Error: \" + e.message;\n        console.error(e);\n    }\n}\n</script>",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div style=\"text-align: center; background: #1a1a1a; padding: 20px; border-radius: 15px; color: white; font-family: sans-serif;\">\n    <h3>M√©todo Sobel (Gradientes de Intensidad)</h3>\n    <video id=\"v_sobel_pro\" width=\"640\" height=\"480\" style=\"display:none\" playsinline></video>\n    <canvas id=\"c_sobel_pro\" width=\"640\" height=\"480\" style=\"background: #000; border: 2px solid #2980b9; border-radius: 10px;\"></canvas>\n    <div style=\"margin-top: 15px;\">\n        <button id=\"btn_on_sobel\" onclick=\"iniciarSobelPro()\" style=\"padding: 10px 20px; background: #2980b9; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold;\">üöÄ ACTIVAR SOBEL</button>\n        <button id=\"btn_off_sobel\" onclick=\"detenerTodo()\" style=\"padding: 10px 20px; background: #e74c3c; color: white; border: none; border-radius: 5px; cursor: pointer; margin-left: 10px; display: none;\">üõë APAGAR</button>\n    </div>\n    <p id=\"log_sobel_pro\" style=\"color: #f1c40f; font-size: 13px; margin-top: 10px;\">Estado: Esperando c√°mara...</p>\n</div>\n\n<script>\n// Implementaci√≥n de Sobel\nfunction applySobelGradients(imageData) {\n    const width = imageData.width;\n    const height = imageData.height;\n    const data = imageData.data;\n\n    // Convertir a escala de grises\n    const gray = new Uint8ClampedArray(width * height);\n    for (let i = 0; i < data.length; i += 4) {\n        const idx = i / 4;\n        gray[idx] = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];\n    }\n\n    // Aplicar Sobel\n    const gradX = new Float32Array(width * height);\n    const gradY = new Float32Array(width * height);\n    const magnitude = new Uint8ClampedArray(width * height);\n\n    for (let y = 1; y < height - 1; y++) {\n        for (let x = 1; x < width - 1; x++) {\n            const idx = y * width + x;\n\n            // Sobel X (detecta bordes verticales)\n            const gx = (\n                -gray[(y-1)*width + (x-1)] + gray[(y-1)*width + (x+1)] +\n                -2*gray[y*width + (x-1)] + 2*gray[y*width + (x+1)] +\n                -gray[(y+1)*width + (x-1)] + gray[(y+1)*width + (x+1)]\n            );\n\n            // Sobel Y (detecta bordes horizontales)\n            const gy = (\n                -gray[(y-1)*width + (x-1)] - 2*gray[(y-1)*width + x] - gray[(y-1)*width + (x+1)] +\n                gray[(y+1)*width + (x-1)] + 2*gray[(y+1)*width + x] + gray[(y+1)*width + (x+1)]\n            );\n\n            gradX[idx] = gx;\n            gradY[idx] = gy;\n\n            // Magnitud del gradiente\n            const mag = Math.sqrt(gx * gx + gy * gy);\n            magnitude[idx] = Math.min(255, mag);\n        }\n    }\n\n    // Convertir a ImageData\n    const output = new ImageData(width, height);\n    for (let i = 0; i < magnitude.length; i++) {\n        output.data[i * 4] = magnitude[i];\n        output.data[i * 4 + 1] = magnitude[i];\n        output.data[i * 4 + 2] = magnitude[i];\n        output.data[i * 4 + 3] = 255;\n    }\n\n    return output;\n}\n\nasync function iniciarSobelPro() {\n    const log = document.getElementById('log_sobel_pro');\n\n    // Detener otros filtros Y limpiar sus canvas\n    detenerTodo();\n\n    // IMPORTANTE: Limpiar TODOS los canvas antes de empezar\n    ['c_canny_pro', 'c_out', 'c_sobel_pro'].forEach(canvasId => {\n        const canvas = document.getElementById(canvasId);\n        if (canvas) {\n            const ctx = canvas.getContext('2d');\n            ctx.clearRect(0, 0, canvas.width, canvas.height);\n            ctx.fillStyle = '#000';\n            ctx.fillRect(0, 0, canvas.width, canvas.height);\n        }\n    });\n\n    try {\n        log.innerText = \"üì∑ Solicitando c√°mara...\";\n\n        const stream = await navigator.mediaDevices.getUserMedia({ \n            video: { width: 640, height: 480, facingMode: 'user' } \n        });\n\n        window.cameraManager.currentStream = stream;\n        window.cameraManager.currentFilter = 'sobel';\n\n        const v = document.getElementById('v_sobel_pro');\n        const canvas = document.getElementById('c_sobel_pro');\n        const ctx = canvas.getContext('2d');\n\n        v.srcObject = stream;\n        await v.play();\n\n        await new Promise(resolve => setTimeout(resolve, 500));\n\n        document.getElementById('btn_on_sobel').style.display = 'none';\n        document.getElementById('btn_off_sobel').style.display = 'inline-block';\n        log.innerText = \"‚úÖ Gradientes Sobel activos\";\n\n        window.cameraManager.activeLoop = true;\n        let frameCount = 0;\n\n        function processFrame() {\n            if (!window.cameraManager.activeLoop || window.cameraManager.currentFilter !== 'sobel') {\n                return;\n            }\n\n            try {\n                ctx.drawImage(v, 0, 0, canvas.width, canvas.height);\n                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n\n                // Aplicar SOBEL\n                const edges = applySobelGradients(imageData);\n\n                ctx.putImageData(edges, 0, 0);\n\n                frameCount++;\n                if (frameCount % 30 === 0) {\n                    log.innerText = \"‚úÖ Sobel activo - Frames: \" + frameCount;\n                }\n\n                requestAnimationFrame(processFrame);\n\n            } catch (e) {\n                console.error('Error:', e);\n                log.innerText = \"‚ùå Error: \" + e.message;\n            }\n        }\n\n        processFrame();\n\n    } catch (e) {\n        log.innerText = \"‚ùå Error: \" + e.message;\n        console.error(e);\n    }\n}\n</script>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "id": "f07f344a-98be-4d8c-8988-2c433dc390c6",
      "cell_type": "markdown",
      "source": "# An√°lisis Matem√°tico: Detecci√≥n de Bordes con el Operador Sobel\n\nEn este segmento del proyecto, hemos implementado el **Operador Sobel** utilizando OpenCV.js. A diferencia de Canny (que es un algoritmo multi-etapa), Sobel es una aplicaci√≥n pura de **C√°lculo Diferencial** adaptado a entornos discretos (im√°genes digitales). A continuaci√≥n, desglosamos la l√≥gica num√©rica que nuestro c√≥digo ejecuta en cada cuadro de video.\n\n### 1. La Imagen como Funci√≥n Discreta\nPara la computadora, una imagen en escala de grises no es \"una foto\", sino una **funci√≥n escalar discreta** $I(x, y)$ que asigna un valor de intensidad (brillo) a cada coordenada.\n* Por ello, el primer paso en nuestro c√≥digo es `cv.cvtColor(..., cv.COLOR_RGBA2GRAY)`. Convertimos el espacio vectorial RGB de 3 dimensiones a un campo escalar de 1 dimensi√≥n para poder derivarlo.\n\n### 2. Diferenciaci√≥n Num√©rica (Diferencias Finitas)\nEn c√°lculo, un borde representa un cambio brusco en la intensidad. Matem√°ticamente, esto corresponde a un **m√°ximo local en la primera derivada** de la funci√≥n de imagen.\nComo la imagen es discreta (p√≠xeles), no podemos calcular derivadas continuas ($\\frac{df}{dx}$). En su lugar, utilizamos **Diferencias Finitas Centrales** mediante la operaci√≥n de **Convoluci√≥n**.\n\nEl c√≥digo calcula dos derivadas parciales independientes:\n\n#### A. Derivada Parcial en X ($G_x$)\nCalcula la tasa de cambio horizontal. Nuestro c√≥digo ejecuta `cv.Sobel(dst, grad_x, cv.CV_16S, 1, 0, 3)`. Esto equivale a convolucionar la imagen con el kernel:\n\n$$\nG_x = \\begin{bmatrix} \n-1 & 0 & +1 \\\\ \n-2 & 0 & +2 \\\\ \n-1 & 0 & +1 \n\\end{bmatrix} * I\n$$\n\n> **Nota t√©cnica:** Usamos `CV_16S` (16-bit signed) porque la derivada puede ser negativa (cuando pasamos de un p√≠xel brillante a uno oscuro). Si us√°ramos 8 bits est√°ndar, los valores negativos se cortar√≠an a 0, perdiendo la mitad de los bordes.\n\n#### B. Derivada Parcial en Y ($G_y$)\nCalcula la tasa de cambio vertical mediante `cv.Sobel(..., 0, 1, 3)`. El kernel rotado es:\n\n$$\nG_y = \\begin{bmatrix} \n-1 & -2 & -1 \\\\ \n0 & 0 & 0 \\\\ \n+1 & +2 & +1 \n\\end{bmatrix} * I\n$$\n\n### 3. C√°lculo de la Magnitud del Gradiente (Norma Vectorial)\nUna vez que tenemos los componentes vectoriales del gradiente $\\nabla I = [G_x, G_y]$, necesitamos calcular la **Magnitud Total** del borde ($G$) para visualizarlo.\n\nLa magnitud real (Euclidiana) se define como:\n$$\n|G| = \\sqrt{G_x^2 + G_y^2}\n$$\n\nSin embargo, calcular ra√≠ces cuadradas para cada uno de los 307,200 p√≠xeles ($640 \\times 480$) es computacionalmente costoso para el navegador en tiempo real.\nEn nuestro c√≥digo, hemos optado por una **Aproximaci√≥n Num√©rica** eficiente utilizando la **Norma $L_1$** (Distancia de Manhattan).\n\nLa l√≠nea `cv.addWeighted(abs_grad_x, 1.0, abs_grad_y, 1.0, ...)` implementa esta suma ponderada:\n\n$$\n|G| \\approx |G_x| + |G_y|\n$$\n\nEsta aproximaci√≥n es mucho m√°s r√°pida y suficientemente precisa para detectar siluetas y contornos en visi√≥n artificial en tiempo real.",
      "metadata": {}
    },
    {
      "id": "397a8e55-0620-440a-824b-d7ae096dba69",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}